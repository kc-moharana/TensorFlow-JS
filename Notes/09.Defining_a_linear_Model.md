# Defining a Model

1. Layers API
2. Define a linear regresion Model
3. inspect the models and loss function
4. Select optimizer and loss function
5. Compile a model

## Machine learning Models
- in abstract sense the Models are representation of the problem statement which can be trained, evaluated and can be used for prediction.
- it is defined using a collection of Layers.
- There are two primary ways of creating models.
  1. **Sequential** — Easiest, works if the models is a simple stack of each layer's input resting on the top of the previous layer's output.
      + input layers <=> output layers
  2. **Model** — Offers more control if the layers need to be wired together in graph-like ways — multiple 'towers', layers that skip a layer, etc.
- The key difference between `tf.model()` and `tf.sequential()` is that `tf.sequential()` is less generic, supporting only a linear stack of layers. `tf.model()` is more generic and supports an arbitrary graph (without cycles) of layers.

## Layers in a model
- Layers are the primary building block for constructing a Model. Each layer will typically perform some computation to transform its input to its output.

### Sequential Model
- `tf.sequential()` : A sequential model is any model where the outputs of one layer are the inputs to the next layer, i.e. the model topology is a simple 'stack' of layers, with no branching or skipping.
  + A model with a stack of layers, feeding linearly from one to the next.
  + `tf.Sequential.add()`: Adds a layer instance on top of the layer stack.
  + `tf.layers.dense (args)`: Creates a dense (fully connected) layer.
    - This layer implements the operation: `output = activation(dot(input, kernel) + bias)`
    - *activation* is the element-wise activation function passed as the activation argument.
    - *kernel* is a weights matrix created by the layer.
    - *bias* is a bias vector created by the layer (only applicable if useBias is true).
  + `tf.LayersModel.compile()`: Configures and prepares the model for training and evaluation.
    - Compiling outfits the model with an optimizer, loss, and/or metrics.
    - Calling fit or evaluate on an un-compiled model will throw an error.


# Linear regression model
- used when the outcome has certain correlation with the input features
  + concluded from a regression analysis: correlation coefficient 
- represent a line by an equation
- `y = mx+c`
- tensor version: `ys = xs.mul(m).add(c)`

## Linear regression using Layers API
- A Layer API has multiple nodes,  a bias unit, activation function and output value.
- for our simple example of a line, we have only one node multiplied with the weight and add the bias.
  + `y = wx + b`
    + *w* = weights
    + *x* = inputs
    + *b* = bias

- we dont need an activation function, so we will use a linear activation function (NOT step function or sigmoid functions that will select specific nodes applying a threshold value) .

```javascript

function createModel(){
  const model = tf.sequential();
  model.add(tf.layers.dense({
    units:1,
    useBias: true,
    activation: 'linear',
    inputDim: 1
  }));
  return model;
}

```

## Inspect a model
- `model.summary()`: Number of layers and parameters.
- `tfvis.show.modelSummary()`: Number of layers and parameters displayed on visor.
- `tf.Layer.getlayer()`: get information about a layer and display using visor.
  + inspect weights for a layer on the tfjs-vis Visor

```javascript
const model = createModel();
model.summary();
tfvis.show.modelSummary({name:"Model Summary"}, model);
const layer = model.getLayer(undefined, 0); // arg1= name, arg2= 0-index based index.
tfvis.show.layer({name:"Layer 1"}, layer);
```

## Compiling a model
- `tf.LayersModel.compile()`: Configures and prepares the model for training and evaluation.
- accepts one sinle object with **loss_function**, **Optimizer** and optional **Metrics** paramaeters.
- Before we can use a model, we need to "compile" it, which sets the optimizer, loss function, and any metrics.

### Loss function
- Evaluates prediction against the data.
- distance of each point from the line.
  - RSME
  - MSE : preferred.
- https://js.tensorflow.org/api/3.6.0/#Training-Losses

### Optimizer
- in the training processes this function attempts to reduce the loss.
- Stochatic Gradient Descent (SGD)
- changes the parameters towards achieving minimum loss iteratively.
  - learning rate is used to define how much to change paramters.
    - lower learning rate: slower processes
    - higher learning rate: overshoot and may never arrive at a minimum loss.
- https://js.tensorflow.org/api/3.6.0/#Training-Optimizers
- `sgd` is good but we need to choose a learning rate (which requires experience and/or experimentation)
- `adam` can be good without a learning rate.

```javascript
// inside createModel()
const optimizer = tf.train.sgd (learningRate=0.1);
model.compile({
  // Computes the mean squared error between two tensors.
  loss: 'meanSquaredError',  
  optimizer
});
```
